%!TEX root = nextndnvideo-tr.tex

\begin{figure*}[htbp]
  \centering
  \includegraphics[scale=0.55]{NDNtube_arch}
  % \vspace{-0.3cm}
  \caption{NDNtube Architecture}
  \label{fig:NDNtube_arch}
  %\vspace{-0.2cm}
\end{figure*}

\section{design goals} % (fold)
\label{sec:design_goals}
UCLA REMAP lab put efforts in building NDNVideo~\cite{ndnvideo} that was one of the first showcases in support of the claim of the possibility of video streaming over NDN. The later changes in the packet format and the development of the new NDN forwarding daemon (NFD~\cite{nfd-guide}) made this implementation of video streaming software obsolete. 

NDNlive and NDNtube is the new effort of UCLA IRL lab to have similar functionality to NDNvideo compatible with the new packet format, new forwarder and new application libraries, such as Consumer / Producer API. The secondary goal of developing these application is to provide more complete examples for application developers learning the new Consumer / Producer API.

The following list contains the key features of NDNlive and NDNtube applications:
\begin{itemize}
\item{\textit{``Live and pre-recorded video\&audio streaming to multiple users''}}

NDNlive provides the live video\&audio streaming to multiple users and guarantees the fluency of the streaming. NDNtube prototypes a Youtube-like user experience: 1) selection of a media from the list of available media resources, and 2) smooth buffered playback. 

\item{\textit{``Random access based on actual location in the video''}}

The video stream is organized as two series of media frames: video and audio. The relationship between playback time and the frame number is non-ambiguous, because both applications use constant frame-rate encoding. In other words, the frame number can be easily calculated from the playback time information and the video and audio frame rate. 

\textbf{ }

\item{\textit{``Synchronized playback''}}

At the moment of data production, each frame is extracted in the form of \textit{GstBuffer}~\cite{Gstbuffer}, which contains playback timestamp information. When audio and video frames are retrieved at the consumer side, video and audio streams are synchronized by Gstreamer library automatically. Another way to achieve synchronization without Gstreamer library is to consider the direct relationship between frame-rate, playback time, and frame numbers.

\item{\textit{``Connection-less and session-less streaming''}}

NDNlive and NDNtube consumers do not try to establish any persistent session or connection with the video publisher. Video and audio frames are fetched from either from in-network cache, or producer's cache, or the permanent storage (e.g. Repo), when producer goes offline.

%\item{\textit{``Archival access to live streams''}}

%The live stream can also be written into the Repo. And Repo will take over the duty of Interest satisfaction. Then the archival access to live stream is possible.

\item{\textit{``Content verification and provenance''}}

Every Data packet must be signed with an asymmetric key of the original publisher in order to reliable authenticate content. Video publishing pipeline outputs so many Data packets that the security component of ndn-cxx library becomes a bottleneck, because of its limited signing speed. In order to achieve the desired signing throughput, both NDNlive and NDNtube producers use Producer API with FAST\_SIGNING option.

\end{itemize} 

% section section_name (end)