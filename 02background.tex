%!TEX root = nextndnvideo-tr.tex



\section{background} % (fold)
In this section, we talk about how NDNlive and NDNtube make use of external NDN and media processing libraries and other major NDN components. 

\label{sec:background}
\subsection{Consumer / Producer API}
\label{ssub:cpapi}

\begin{figure*}
  \centering
  \includegraphics[scale=0.55]{NDNlive_arch}
  % \vspace{-0.3cm}
  \caption{NDNlive Architecture}
  \label{fig:NDNlive_arch}
  %\vspace{-0.2cm}
\end{figure*}

Consumer-Producer API~\cite{api-tr}\cite{cp-icn} provides a generic programming interface to NDN communication protocols and architectural modules. A consumer context associates an NDN name prefix with various data fetching, transmission, and content verification parameters, and integrates processing of Interest and Data packets on the consumer side. A producer context associates an NDN name prefix with various packet framing, caching, content-based security, and namespace registration parameters, and integrates processing of Interest and Data packets on the producer side.

In NDNlive and NDNtube, the video publisher consists of multiple producers generating video and audio frames separately. The corresponding video players consist of multiple consumers sending Interests for the video and audio frames. Consumer / Producer API simplifies the application logic at both sides: media production and media consumption. Since video frames are too large to be encapsulated by a single Data packet, the media production pipeline has to include a content segmentation step in order to split the content into multiple Data packets. Producer API provides this segmentation functionality. At the same time, since a video frame cannot be retrieved by a single Interest packet, UDR and RDR protocols behind the Consumer API automatically pipeline Interest packets and solve other tasks related to the retrieval of the application frame. 
%In the case of MPEG-DASH, all these low-level details are handled by the HTTP / TCP protocol machinery. 
We will talk about the implementation details in Section~\ref{sec:implementation}.

\subsection{Gstreamer}

We use Gstreamer~\cite{gstreamer} to handle the media processing part. 

In NDNlive, raw video images captured by the camera are transferred to the \textit{Encoder\_v} component and are encoded into \textit{H264} format. Then the encoded video is passed to the \textit{Parser\_v} to be parsed into frames (\textit{B, P or I frame}). The microphone captures the raw audio, which is passed to the \textit{Encoder\_a}. The encoder component encodes the raw audio into \textit{AAC} format. The encoded audio stream is transferred to the \textit{Parser\_a} to be parsed into audio frames, which are passed to the Producer API for any possible segmentation. Video and audio data is retrieved frame by frame that are passed to the video \textit{Decoder\_v} and audio \textit{Decoder\_a} for the decoding into the format which the video \textit{Player\_v} or audio \textit{Player\_a} can play.

In NDNtube, the source for video and audio streams is an mp4 file containing \textit{H264} video and \textit{AAC} audio. Gstreamer opens the file and passes it to the \textit{Demuxer} component to separate video and audio streams. Since the video file is already encoded, the media processing pipeline does not have an \textit{Encoder} component in it. The encoded video or audio streams are separately pushed into the \textit{Parser} to generate video and audio frames.

%Because we need to extract the frames from the video source, so now we only support \textit{H264} video encoded format and  encoded format for NDNlive and \textit{MP4} file format for NDNtube. 

\subsection{Repo}
\label{sec:repo}
NDNlive streams the captured video and audio non-stop. Therefore, the media publisher just keeps producing new frames and does not care about the data it produced several minutes ago. The consumer is also interested only in recent video and audio frames. As long as the producer is attached to the NDN network, it  will serve the incoming Interests. %The consumer can get the data back and play them back immediately.

NDNtube publishes the video only once --- all Data packets corresponding to audio and video frames are permanent and never change after the initial publication. Since the same video could be requested multiple times by different users, it is reasonable to store the produced Data packets in a `database' which is exposed to the requests from the network. Otherwise, every time a different user requests the same video, the corresponding video and audio Data packets would have to be republished (and signed) in case NDN cache has not been able to satisfy these Interests.

Repo-ng~\cite{repo-ng} is used as a permanent storage for the video and audio content. Repo-ng (repo-new generation) is an implementation of NDN persistent in-network storage, which exposes a Repo protocol~\cite{Repo-Protocol} allowing write access to applications. Repo insertion is natively supported by the Producer API with \textit{LOCAL\_REPO} option (if repo is running on the local host) or \textit{REMOTE\_REPO\_PREFIX} option to point to the right remote repo by its name prefix. 
% section section_name (end)

\textbf{ }

\textbf{ }